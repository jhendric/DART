<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
          "http://www.w3.org/TR/html4/strict.dtd">
<HTML>
<HEAD>
<TITLE>AIRS Observations</TITLE>
<link rel="stylesheet" type="text/css" href="../../doc/html/doc.css" />
</HEAD>
<BODY>
<A NAME="TOP"></A>

<H1>AIRS Observations</H1>

<table border=0 summary="" cellpadding=5>
<tr>
    <td valign=middle>
    <img src="../../doc/html/Dartboard7.png" alt="DART project logo" height=70 />
    </td>
    <td>
       <P>Jump to <a href="../../index.html">DART Documentation Main Index</a><br />
          <small><small>version information for this file: <br />
          <!-- version tag follows, do not edit -->
          $Id$</small></small>
       </P></td>
</tr>
</table>

<A HREF="#DataSources">DATA SOURCES</A> /
<A HREF="#Programs">PROGRAMS</A> / 
<A HREF="#Modules">MODULES</A> /
<A HREF="#Namelist">NAMELIST</A> /
<A HREF="#Errors">ERRORS</A> /
<A HREF="#FuturePlans">FUTURE PLANS</A> /
<A HREF="#Legalese">TERMS OF USE</A>

<H2>Overview</H2>


<P>
The <a href="http://airs.jpl.nasa.gov/">AIRS</a>
instrument is an Atmospheric Infrared Sounder flying on the
<a href="http://aqua.nasa.gov/">Aqua</a> spacecraft.
Aqua is one of a group of satellites flying close together
in a polar orbit, collectively known as the "A-train".
The programs in this directory help to extract the
data from the distribution files and put them into
DART observation sequence (obs_seq) file format.
<br />
<br />
AIRS data includes atmospheric temperature in the troposphere,
derived moisture profiles, land and ocean surface temperatures,
surface emmissivity, cloud fraction, cloud top height,
and ozone burden in the atmosphere.
</P>

<!--==================================================================-->

<A NAME="DataSources"></A>
<HR />
<H2>DATA SOURCES</H2>

<P>
Access to the web pages where the
AIRS data are stored is available by
<a href="http://airs.jpl.nasa.gov/data_products/get_AIRS_data/">registering</a>
as a data user.
</P>

<P>
More detailed information on the 
<a href="http://disc.sci.gsfc.nasa.gov/AIRS/data-holdings/by-data-product/airsL2_Std.shtml">
Level 2 standard product (AIRX2RET) data</a>
is available.
</P>

<P>
The data is distributed in
<a href="http://www.hdfgroup.org/">HDF-4</a> format, using
some additional conventions for metadata called
<a href="http://hdfeos.org/software.php">HDF-EOS</a>.
There is a basic library for accessing data in hdf files,
and a variety of
<a href="http://www.hdfgroup.org/products/index.html">generic tools</a>
that work with hdf files.
Besides the programs in this directory, a variety of
<a href="http://disc.sci.gsfc.nasa.gov/AIRS/tools.shtml">specific tools</a>
targeted at AIRS data are available to help read and browse the data.
General information on using hdf in the earth sciences is available
<a href="http://eosweb.larc.nasa.gov/HBDOCS/hdf.html">here</a>.
</P>

<P>
Several types of AIRS data, with varying levels of processing, are available.
The following descriptions are taken from the
<a href="http://disc.sci.gsfc.nasa.gov/AIRS/documentation/v5_docs/AIRS_V5_Release_User_Docs/V5_Data_Release_UG.pdf">V5_Data_Release_UG</a> document:
</P>

<BLOCKQUOTE>
<P>
The L1B data product includes geolocated, calibrated observed microwave,
infrared and visible/near infrared radiances, as well as Quality Assessment
(QA) data.  The radiances are well calibrated; however, not all QA data have
been validated.  Each product granule contains 6 minutes of data.  Thus there
are 240 granules of each L1B product produced every day.
</P>

<P>
The L2 data product includes geolocated, calibrated cloud-cleared radiances
and 2-dimensional and 3-dimensional retrieved physical quantities (e.g.,
surface properties and temperature, moisture, ozone, carbon monoxide and
methane profiles throughout the atmosphere).  Each product granule contains 6
minutes of data.  Thus there are 240 granules of each L2 product produced
every day.
</P>

<P>
The L3 data are created from the L2 data product by binning them in
1&deg;x1&deg;
grids.  There are three products: daily, 8-day and monthly.  Each product
provides separate ascending (daytime) and descending (nighttime) binned data
sets.
</P>
</BLOCKQUOTE>

<P>
The converter in this directory processes level 2 (L2) data files, using
data set <tt>AIRS_DP</tt> and data product <tt>AIRX2RET</tt> without
<tt>HSB</tt> (the instrument measuring humidity which failed).
</P>

<P>
The Atmospheric Infrared Sounder (AIRS) is a facility instrument aboard
the second Earth Observing System (EOS) polar-orbiting platform,
EOS Aqua. In combination with the Advanced Microwave Sounding Unit
(AMSU) and the Humidity Sounder for Brazil (HSB), AIRS constitutes an
innovative atmospheric sounding group of visible, infrared, and microwave
sensors. AIRS data will be generated continuously. Global coverage will
be obtained twice daily (day and night) on a 1:30pm sun synchronous orbit
from a 705-km altitude.

The AIRS Standard Retrieval Product consists of retrieved estimates of cloud
and surface properties, plus profiles of retrieved temperature, water vapor,
ozone, carbon monoxide and methane. Estimates of the errors associated with
these quantities will also be part of the Standard Product. The temperature
profile vertical resolution is 28 levels total between 1100 mb and 0.1 mb,
while moisture profile is reported at 14 atmospheric layers between 1100
mb and 50 mb. The horizontal resolution is 50 km. An AIRS granule has been
set as 6 minutes of data, 30 footprints cross track by 45 lines along track.

(The Shortname for this product is AIRX2RET).
</P>

<P>
Getting the data currently means putting in a start/stop time at
<a href="http://mirador.gsfc.nasa.gov/cgi-bin/mirador/homepageAlt.pl?keyword=AIRX2RET">this web page</a>.  The keyword is <tt>AIRX2RET</tt> and put in
the time range of interest and optionally a geographic region.  
Each file contains 6 minutes of data, is
about 2.3 Megabytes, and globally there are 240 files/day 
(about 550 Megabytes/day).
There are additional options for getting only particular variables of
interest, but the current reader expects whole files to be present.
Depending on your connection to the internet, there are various options
for downloading.  We have chosen to download a <tt>wget</tt> script which is
created by the web page after adding the selected files to a 'cart' 
and 'checking out'.  The script has a series of <tt>wget</tt> commands
which downloads each file, one at a time, which is run on the machine
where you want the data to end up.

<!--==================================================================-->

<A NAME="Programs"></A>
<HR />
<H2>PROGRAMS</H2>

<P>
The temperature observations are located on standard levels; there is a
single array of heights in each file and all temperature data is located
on one of these levels.  The moisture observations, however, are an
integrated quantity for the space between the levels; in their terminology
the fixed heights are 'levels' and the space between them are 'layers'.
The current converter locates the moisture obs at the midpoint, in log
space, between the levels.  A more accurate computation of moisture would
be to add metadata to the moisture obs with a number of points between
the layers and have the forward operator integrate the real moisture
values at intermediate points from the model and sum the moisture.
We have not written the more complex forward operator because
at this point we're getting reasonable results from the better-located
moisture obs (the first version of this converter incorrectly located
them at the lower level instead of the middle of the layer).
</P>
<P>
The hdf files need to be downloaded from the data server, in any manner
you choose.   The converter program reads each hdf granule and outputs
a DART obs_seq file containing up to 56700 observations.  Only those with
a quality control of 0 (Best) are kept.
The resulting obs_seq files can be merged with the 
<a href="../../obs_sequence/obs_sequence_tool.html">obs_sequence_tool</a> 
into larger time periods.
</P>
<P>
The scripts directory here includes some shell scripts that
make use of the fact that the AIRS data is also archived on the NCAR
HPSS (tape library) in daily tar files.  The script has options 
to download a day of granule files, convert them, merge them 
into daily files, and remove the
original data files and repeat the process for any specified
time period.  (See <tt>oneday_down.sh</tt>)
</P>

<!--==================================================================-->
<!-- Describe the bugs.                                               -->
<!--==================================================================-->

<A NAME="KnownBugs"></A>
<BR /><HR /><BR />
<H2>KNOWN BUGS</H2>
<P>
none
</P>

<!--==================================================================-->
<!-- Descibe Future Plans.                                            -->
<!--==================================================================-->

<A NAME="FuturePlans"></A>
<BR /><HR /><BR />
<H2>FUTURE PLANS</H2>
<P>
none
</P>

<!--==================================================================-->
<!-- Legalese & Metadata                                              -->
<!--==================================================================-->

<A NAME="Legalese"></A>
<HR />
<H2>Terms of Use</H2>

<P>
DART software - Copyright 2004 - 2011 UCAR.<br />
This open source software is provided by UCAR, "as is",<br />
without charge, subject to all terms of use at<br />
<a href="http://www.image.ucar.edu/DAReS/DART/DART_download">
http://www.image.ucar.edu/DAReS/DART/DART_download</a>
</P>

<TABLE border=0 cellpadding=0 width=100% summary="">
<TR><TD valign=top>Contact:       </TD><TD> nancy collins </TD></TR>
<TR><TD valign=top>Revision:      </TD><TD> $Revision$ </TD></TR>
<TR><TD valign=top>Source:        </TD><TD> $URL$ </TD></TR>
<TR><TD valign=top>Change Date:   </TD><TD> $Date$ </TD></TR>
<TR><TD valign=top>Change&nbsp;history:&nbsp;</TD><TD> try "svn&nbsp;log" or "svn&nbsp;diff" </TD></TR>
</TABLE>

<!--==================================================================-->

</BODY>
</HTML>
