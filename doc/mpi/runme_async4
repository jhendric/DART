#!/bin/tcsh
#
# Data Assimilation Research Testbed -- DART
# Copyright 2004-2007, Data Assimilation Research Section
# University Corporation for Atmospheric Research
# Licensed under the GPL -- www.gpl.org/licenses/gpl.html

# <next few lines under version control, do not edit>
# $URL$
# $Id$
# $Revision$
# $Date$

# start this script like:
#   bsub < runme   (for lsf)
#   qsub runme     (for pbs)
#   ./runme        (for everything else)

#----------------------------------------------------------------------
#### LSF options for BSUB
### -J      job name    (master script job.csh presumes filter.xxxx.log)
### -o      output listing filename 
### -P      account number
### -q      queue
### -n      number of tasks (processors)
### -x      exclusive use of node
### -R "span[ptile=(num procs you want on each node)]"
#
#BSUB -J ftest
#BSUB -o f.log
#BSUB -e f.err
#BSUB -q regular
#BSUB -n 4
#----------------------------------------------------------------------


#----------------------------------------------------------------------
# directives to allow this to run as a batch jobs under PBS.
#PBS -N ftest
#PBS -r n
#PBS -e f.err
#PBS -o f.log
#PBS -q small
#PBS -l nodes=4
#----------------------------------------------------------------------

echo current directory is `pwd`
echo current script host is `hostname`

if ( $?LSB_HOSTS) then

   mpirun.lsf ./ftest_stop &    # notice this is backgrounded
   sleep 10
   mpirun.lsf ./ftest_go

else if ( $?PBS_O_WORKDIR) then

   mpirun ./ftest_stop &        # notice this is backgrounded
   sleep 10
   mpirun ./ftest_go

else

   mpirun -np 4 -nolocal ./ftest_stop &     # backgrounded
   sleep 10
   mpirun -np 4 -nolocal ./ftest_go

endif

